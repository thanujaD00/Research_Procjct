{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a2cbb0-b158-48b4-a99e-103e144b3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Separation Summary:\n",
      "Undercooked images: 527\n",
      "Overcooked images: 513\n",
      "Perfectly-cooked images: 520\n",
      "\n",
      "Total processed images: 1560\n",
      "Unprocessed images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def separate_copra_images(base_path):\n",
    "    \"\"\"\n",
    "    Separate copra images into class-specific folders from train, valid, test subfolders.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Base directory containing train, valid, test folders\n",
    "    \"\"\"\n",
    "    # Subfolders to process\n",
    "    subfolders = ['train', 'valid', 'test']\n",
    "    \n",
    "    # Base output directory for class-specific folders\n",
    "    output_base = os.path.join(base_path, 'sorted_classes')\n",
    "    \n",
    "    # Create output directories for each class\n",
    "    classes = ['undercooked', 'overcooked', 'perfectly-cooked']\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(output_base, cls), exist_ok=True)\n",
    "    \n",
    "    # Track processed images\n",
    "    processed_images = {cls: [] for cls in classes}\n",
    "    unprocessed_images = []\n",
    "    \n",
    "    # Process each subfolder\n",
    "    for subfolder in subfolders:\n",
    "        # Full path to subfolder\n",
    "        subfolder_path = os.path.join(base_path, subfolder)\n",
    "        \n",
    "        # Path to CSV in this subfolder\n",
    "        csv_path = os.path.join(subfolder_path, '_annotations.csv')\n",
    "        \n",
    "        # Check if CSV exists\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"No CSV found in {subfolder} folder. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Iterate through the CSV and move images\n",
    "        for _, row in df.iterrows():\n",
    "            filename = row['filename']\n",
    "            image_class = row['class']\n",
    "            \n",
    "            # Full paths\n",
    "            source_image_path = os.path.join(subfolder_path, filename)\n",
    "            dest_image_path = os.path.join(output_base, image_class, filename)\n",
    "            \n",
    "            try:\n",
    "                # Check if source image exists\n",
    "                if os.path.exists(source_image_path):\n",
    "                    # Copy image to class-specific folder\n",
    "                    shutil.copy2(source_image_path, dest_image_path)\n",
    "                    processed_images[image_class].append(filename)\n",
    "                else:\n",
    "                    unprocessed_images.append(filename)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nImage Separation Summary:\")\n",
    "    for cls in classes:\n",
    "        print(f\"{cls.capitalize()} images: {len(processed_images[cls])}\")\n",
    "    \n",
    "    print(f\"\\nTotal processed images: {sum(len(imgs) for imgs in processed_images.values())}\")\n",
    "    print(f\"Unprocessed images: {len(unprocessed_images)}\")\n",
    "    \n",
    "    # Optional: Log unprocessed images\n",
    "    if unprocessed_images:\n",
    "        with open(os.path.join(output_base, 'unprocessed_images.txt'), 'w') as f:\n",
    "            f.write('\\n'.join(unprocessed_images))\n",
    "        print(\"\\nList of unprocessed images saved to unprocessed_images.txt\")\n",
    "\n",
    "# Set the base path\n",
    "base_path = r'C:\\Users\\ASUS VIVOBOOK\\Downloads\\updated dataset unaugmented.v2-new-dataset.tensorflow'\n",
    "\n",
    "# Run the separation function\n",
    "separate_copra_images(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4267259-1f41-42d7-a601-394b85ec7e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
